import streamlit as st 
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from src.sequence_creator import create_sequences, create_shifting_sequences
from src.model_exp import LSTM_EIR, LSTM_Incidence
import time


log_transform = lambda x: np.log(x + 1e-8)
inverse_log_transform = lambda x: np.exp(x) - 1e-8


# Set page configuration
st.set_page_config(
    page_title="Malaria Estimator",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply a modern Seaborn theme
sns.set_style("darkgrid")  
plt.style.use("ggplot")

# Custom CSS for better UI
st.markdown("""
    <style>
        /* Customize headers */
        h1 {
            color: #FF4B4B;
            text-align: center;
        }
        /* Improve widgets */
        .stButton>button {
            background-color: #4CAF50;
            color: white;
            border-radius: 8px;
            font-size: 16px;
        }
        .stButton>button:hover {
            background-color: #45a049;
        }
        /* Adjust sidebar */
        [data-testid="stSidebar"] {
            background-color: #2E3B4E;
            color: white;
        }
    </style>
""", unsafe_allow_html=True)

# Function to load model
@st.cache_resource
def load_models(model_eir_path, model_inc_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    model_eir = LSTM_EIR(input_size=1, architecture=[256, 128, 64, 32])
    model_eir.load_state_dict(torch.load(model_eir_path, map_location=device))
    model_eir.to(device)
    model_eir.eval()

    model_inc = LSTM_Incidence(input_size=2, architecture=[256, 128, 64, 32])
    model_inc.load_state_dict(torch.load(model_inc_path, map_location=device))
    model_inc.to(device)
    model_inc.eval()

    return model_eir, model_inc, device

# Function to preprocess data
def preprocess_data(df):

    # Sanity Check for selected prevalence column
    if not pd.api.types.is_numeric_dtype(df['prev_true']):
        st.error("üö® The selected prevalence column is invalid. It contains non-numeric values.")
        return None, False  # Return None to indicate failure
    
    has_true_values = {'EIR_true', 'incall'}.issubset(df.columns)

    if has_true_values:
        df_scaled = df[['prev_true', 'EIR_true', 'incall']].apply(log_transform)
    else:
        df_scaled = df[['prev_true']].apply(log_transform)
    
    return df_scaled, has_true_values

# Function to convert time column
def convert_time_column(df, time_column):
    try:
        if pd.api.types.is_numeric_dtype(df[time_column]):
            return df[time_column].astype(float) / 365.25  # Convert days to years
        else:
            df[time_column] = pd.to_datetime(df[time_column], errors='coerce', format='%b-%y')  # Example: "Jan-16"
            
            if df[time_column].isna().all():
                st.error("Could not parse the time column. Ensure it's a proper date format (e.g., Jan-16).")
                return None
        
            start_year = df[time_column].dt.year.min()
            df['time_in_years'] = df[time_column].dt.year + (df[time_column].dt.month - 1) / 12 - start_year

        if len(df['time_in_years']) != len(df):
            st.error(f"üö® Mismatch error, possibly due to invalid time column selection'{time_column}' ‚Äì expected {len(df)} values but found {len(df['time_in_years'])}. "
                     "Please verify your dataset.")
            return None
        return df['time_in_years']
    
    except Exception as e:
        st.error(f"Error in converting time column: {e}")
        return None
    
@st.cache_data(show_spinner="üîÑ Running model predictions...")
def generate_predictions_per_run(data, selected_runs, run_column, window_size, _model_eir, _model_inc, _device, has_true_values):
    run_results = {}

    for run in selected_runs:
        run_data = data[data[run_column] == run]
        if run_data.empty:
            continue

        scaled_data, _ = preprocess_data(run_data)
        if scaled_data is None:
            continue

        X_eir_scaled, y_eir = create_sequences(scaled_data, window_size)
        if len(X_eir_scaled) == 0:
            continue

        X_eir_scaled = X_eir_scaled.to(_device)
        with torch.no_grad():
            eir_preds_scaled = _model_eir(X_eir_scaled.unsqueeze(-1))
            eir_preds_unscaled = inverse_log_transform(eir_preds_scaled.cpu().numpy())

        prev_series_scaled = scaled_data['prev_true'].values[:len(eir_preds_scaled)]

        inc_input_df_scaled = pd.DataFrame({
            'prev_true': prev_series_scaled,
            'EIR_true': scaled_data['EIR_true'].values[:len(eir_preds_scaled)] if 'EIR_true' in scaled_data.columns else eir_preds_scaled[:, 0].cpu().numpy()
        })# This is not absolutely right (at the moment) interms of actual versus predicted EIR

        X_inc_input, _ = create_shifting_sequences(inc_input_df_scaled, window_size)
        X_inc_input = X_inc_input.to(_device)

        with torch.no_grad():
            inc_preds_scaled = _model_inc(X_inc_input)
            inc_preds_unscaled = inverse_log_transform(inc_preds_scaled.cpu().numpy())

        run_results[run] = {
            "eir_preds_scaled": eir_preds_scaled.cpu().numpy(),
            "eir_preds_unscaled": eir_preds_unscaled,
            "inc_preds_unscaled": inc_preds_unscaled,
            "scaled_data": scaled_data,
            "original_data": run_data,
            "y_eir_true": y_eir.cpu().numpy() if y_eir is not None else None
        }

    return run_results

@st.cache_data
def compute_global_yaxis_limits(run_results):
    all_prev, all_eir, all_inc = [], [], []

    for result in run_results.values():
        #scaled_data = result['scaled_data']
        run_data = result["original_data"]
        all_prev.extend(run_data['prev_true'].values)
        all_inc.extend(result['inc_preds_unscaled'][:, 0])
        all_eir.extend(result['eir_preds_unscaled'][:, 0])

    prev_min, prev_max = 0, max(all_prev) * 1.1 if all_prev else (0, 1)
    eir_min, eir_max = 0, max(all_eir) * 1.1 if all_eir else (0, 1)#550  # Can be dynamic too
    inc_min, inc_max = 0, max(all_inc) * 1.1 if all_inc else (0, 1)

    return (prev_min, prev_max), (eir_min, eir_max), (inc_min, inc_max)


def plot_predictions(run_results, run_column, time_column, selected_runs, 
                     log_eir, log_inc, log_all, prev_limits, eir_limits, inc_limits):

    is_string_time = not pd.api.types.is_numeric_dtype(
        next(iter(run_results.values()))['original_data'][time_column]
    )

    if is_string_time:
        time_labels = next(iter(run_results.values()))['original_data'][time_column].unique()
        time_values = np.arange(len(time_labels))
    else:
        time_values = next(iter(run_results.values()))['original_data'][time_column].astype(float) / 365.25
        time_labels = None

    num_plots = len(selected_runs)
    fig, axes = plt.subplots(num_plots, 3, figsize=(18, 5 * num_plots), sharex=True)
    if num_plots == 1:
        axes = np.expand_dims(axes, axis=0)

    colors = sns.color_palette("muted", 3)
    data_to_download = []

    prev_min, prev_max = prev_limits
    eir_min, eir_max = eir_limits
    inc_min, inc_max = inc_limits

    for i, run in enumerate(selected_runs):
        result = run_results.get(run)
        if result is None:
            st.warning(f"‚ö†Ô∏è No prediction result available for run '{run}'")
            continue

        eir_preds_unscaled = result["eir_preds_unscaled"]
        inc_preds_unscaled = result["inc_preds_unscaled"]
        scaled_run_data = result["scaled_data"]
        run_data = result["original_data"]
        y_eir_unscaled = inverse_log_transform(result["y_eir_true"]) if result["y_eir_true"] is not None else None

        has_inc_true = 'incall' in scaled_run_data.columns
        y_inc_unscaled = None
        if has_inc_true:
            X_inc_all, y_inc = create_shifting_sequences(
                scaled_run_data[['prev_true', 'EIR_true', 'incall']], window_size=10
            )
            y_inc_unscaled = inverse_log_transform(y_inc.numpy())

        time_values_plot = time_values[:len(eir_preds_unscaled)]
        min_len = len(eir_preds_unscaled)#len(time_values_plot)

        plot_data = []

        # Prevalence (true only, no prediction)
        plot_data.append({
            "title": "Prevalence",
            "pred": None,  # No estimated prevalence
            "true": run_data['prev_true'].values[:min_len]
        })

        # EIR
        plot_data.append({
            "title": "EIR",
            "pred": eir_preds_unscaled[:min_len, 0],
            "true": y_eir_unscaled[:min_len, 0] if y_eir_unscaled is not None else None
        })

        # Incidence
        plot_data.append({
            "title": "Incidence",
            "pred": inc_preds_unscaled[:min_len, 0],
            "true": y_inc_unscaled[:min_len, 0] if y_inc_unscaled is not None else None
        })

        log_scales = {
            "Prevalence": log_all,
            "EIR": log_eir or log_all,
            "Incidence": log_inc or log_all
        }

        y_limits = {
            "Prevalence": (prev_min, prev_max),
            "EIR": (eir_min, eir_max),
            "Incidence": (inc_min, inc_max)
        }

        for ax, data, color in zip(axes[i], plot_data, colors):
            title = data["title"]
            pred = data["pred"]
            true = data["true"]

            x_vals = time_values_plot#[:len(true)]

            # Only plot prediction for EIR and Incidence
            if title != "Prevalence" and pred is not None:
                ax.plot(x_vals, pred, linestyle="--", color=color,
                        label=f"Estimated {title}", linewidth=2.5)

            # Always plot true values (black)
            if true is not None:
                ax.plot(x_vals, true, color="black", linestyle="-",
                        label=f"True {title}", linewidth=2)

            if log_scales[title]:
                ax.set_yscale('log')

            ax.set_ylim(*y_limits[title])
            ax.set_title(f"{run} - {title}", fontsize=14, color="#FF4B4B")
            ax.set_ylabel(title, fontsize=12)
            ax.legend()

        data_to_download.append(pd.DataFrame({
            "Prevalence": plot_data[0]["true"],
            "Estimated EIR": plot_data[1]["pred"],
            "Estimated Incidence": plot_data[2]["pred"]
        }))

    for ax in axes[-1]:
        if is_string_time:
            tick_indices = np.arange(0, len(time_values_plot), step=6, dtype=int)
            ax.set_xticks(time_values_plot[tick_indices])
            ax.set_xticklabels(np.array(time_labels)[tick_indices], rotation=45, fontsize=10)
        else:
            ax.set_xlabel("Years", fontsize=12)

    plt.tight_layout()
    st.pyplot(fig)

    if data_to_download:
        combined_data = pd.concat(data_to_download, keys=selected_runs, names=[run_column, "Index"])
        csv_data = combined_data.to_csv(index=False).encode('utf-8')
        st.download_button("üì• Download Estimates as CSV", data=csv_data, file_name="predictions.csv", mime="text/csv")



# Streamlit UI
st.title("üî¨ Malaria Incidence and EIR Estimator with AI - 2 Models")


# Choose data source
data_source = st.radio("üìä Select data source", ("Upload my own data", "Use preloaded test data"))

# Load the data accordingly
if data_source == "Use preloaded test data":
    remote_url = "https://raw.githubusercontent.com/Olatundemi/MalariaEmulator/main/test/ANC_Simulation_1000_test_runs.csv"

    try:
        test_data = pd.read_csv(remote_url)
        st.success("‚úÖ Preloaded test data loaded successfully!")
    except Exception as e:
        st.error(f"Failed to load preloaded data: {e}")
        st.stop()
else:
    uploaded_file = st.file_uploader("üìÇ Upload prevalence data to estimate (CSV)", type=["csv"])
    if uploaded_file:
        test_data = pd.read_csv(uploaded_file)
    else:
        st.warning("Please upload a CSV file to continue.")
        st.stop()

columns = test_data.columns.tolist()

run_column = st.selectbox("üîÑ Select geographical unit(s) e.g. Region, District, Province...", columns) if 'run' not in columns else 'run'

time_column = st.selectbox("üïí Select time column", columns) if 't' not in columns else 't'

unique_runs = test_data[run_column].unique()
selected_runs = st.multiselect(f"üìä Select {run_column}(s) to estimate", unique_runs, default=unique_runs[:0])

# Filter the data based on selected runs
filtered_data = test_data[test_data[run_column].isin(selected_runs)]

if 'prev_true' not in columns:
    
    prevalence_column = st.selectbox("ü©∏ Select the column corresponding to prevalence", columns)#, key=f"prevalence_select_{key_suffix}")
    test_data = test_data.rename(columns={prevalence_column: 'prev_true'})

#model_path = #"src/trained_model/4_layers_model.pth"
window_size = 10
model_eir_path = "C:/Users/oibrahim/Documents/MalariaEmulator/src/trained_model/shifting_sequences/LSTM_EIR_4_layers_10000run_W10.pth"
model_inc_path = "C:/Users/oibrahim/Documents/MalariaEmulator/src/trained_model/shifting_sequences/LSTM_Incidence_4_layer_10000run_W10_shifting_sequence.pth"
model_eir, model_inc, device = load_models(model_eir_path, model_inc_path)

df_scaled, has_true_values = preprocess_data(test_data)

if df_scaled is None:
    st.stop()  # Stop further execution if preprocessing fails
    
log_eir = st.checkbox("üìà View EIR on Log Scale", value=False)
log_inc = st.checkbox("üìâ View Incidence on Log Scale", value=False)
log_all = st.checkbox("üîç View All Plots on Log Scale", value=False)


if selected_runs:
    start_time = time.time()
    run_results = generate_predictions_per_run(
        test_data, selected_runs, run_column, window_size, model_eir, model_inc, device, has_true_values
    )
    st.info(f"‚úÖ Predictions computed in {time.time() - start_time:.2f} seconds")

    if not run_results:
        st.warning("No valid predictions could be generated.")
        st.stop()

    start_time = time.time()
    prev_limits, eir_limits, inc_limits = compute_global_yaxis_limits(run_results)
    st.info(f"‚úÖ Axis limits calculated in {time.time() - start_time:.2f} seconds")

    start_time = time.time()
    plot_predictions(
        run_results, run_column, time_column, selected_runs,
        log_eir, log_inc, log_all, prev_limits, eir_limits, inc_limits
    )
    st.info(f"‚úÖ Plots generated in {time.time() - start_time:.2f} seconds")